{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StopwordsRemoval.StopwordsRemover import StopwordsRemover\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '아')\n(3, '아')\n(5, '제')\n(9, '영')\n(12, '자')\n(16, '우리')\n(17, '나')\n(20, '가')\n(22, '의')\n(39, '을')\n(41, '나')\n(51, '의')\n(54, '가')\n(58, '가')\n(69, '으로')\n(69, '로')\n(71, '나')\n(75, '.')\n(78, '1')\n(79, '8')\n(80, '일')\n(83, '제')\n(85, '제')\n(88, '(')\n(92, ')')\n(93, '에')\n(103, '3')\n(110, '가')\n(112, '의')\n(119, '1')\n(120, '2')\n(121, '.')\n(122, '7')\n(123, '%')\n(124, '로')\n(135, '0')\n(136, '.')\n(137, '1')\n(138, '%')\n(147, '.')\n(152, '이')\n(158, '것')\n(163, '에')\n(175, '이')\n(183, '것')\n(184, '을')\n(186, '의')\n(190, '.')\n(196, '가')\n(198, '의')\n(209, '1')\n(211, '9')\n(212, '월')\n(214, '사')\n(215, '이')\n(217, '0')\n(218, '.')\n(219, '3')\n(220, '%')\n(234, '사')\n(242, '1')\n(243, '7')\n(255, '이')\n(257, '가')\n(262, '.')\n(264, '이')\n(272, '과')\n(277, '이')\n(278, '가')\n(280, '각')\n(281, '각각')\n(281, '각')\n(283, '0')\n(284, '.')\n(285, '2')\n(286, '%')\n(290, ',')\n(297, '가')\n(299, '0')\n(300, '.')\n(301, '1')\n(302, '%')\n(310, '.')\n(312, '이')\n(314, '에')\n(319, '이')\n(323, '나')\n(325, '하')\n(329, '.')\n(339, '가')\n(356, '.')\n(366, '3')\n(380, '가')\n(389, '이')\n(391, '9')\n(392, '4')\n(393, '.')\n(394, '4')\n(395, '%')\n(396, '로')\n(405, '0')\n(406, '.')\n(407, '6')\n(408, '%')\n(414, '가')\n(417, '.')\n(426, '가')\n(440, '(')\n(441, '1')\n(442, '2')\n(443, '7')\n(444, '.')\n(445, '6')\n(446, '%')\n(447, ')')\n(448, ',')\n(452, '(')\n(453, '1')\n(454, '2')\n(455, '0')\n(456, '.')\n(457, '9')\n(458, '%')\n(459, ')')\n(460, ',')\n(465, '(')\n(466, '1')\n(467, '1')\n(468, '6')\n(469, '.')\n(470, '8')\n(471, '%')\n(472, ')')\n(473, ',')\n(475, '네')\n(479, '(')\n(480, '1')\n(481, '0')\n(482, '6')\n(483, '%')\n(484, ')')\n(485, ',')\n(490, '이')\n(491, '(')\n(492, '1')\n(493, '0')\n(494, '2')\n(495, '%')\n(498, ')')\n(499, ',')\n(502, '나')\n(504, '(')\n(505, '1')\n(506, '0')\n(507, '0')\n(508, '.')\n(509, '4')\n(510, '%')\n(511, ')')\n(512, '에')\n(514, '이')\n(515, '어')\n(518, '사')\n(523, '4')\n(524, '3')\n(527, '가')\n(531, '7')\n(534, '를')\n(540, '.')\n(545, '의')\n(554, '가')\n(563, '2')\n(564, '0')\n(565, '1')\n(566, '4')\n(567, '년')\n(569, '2')\n(572, '를')\n(577, '으로')\n(577, '로')\n(579, '1')\n(580, '4')\n(595, '.')\n(598, '사')\n(602, '4')\n(603, '3')\n(607, '가')\n(613, '에')\n(615, '이')\n(616, '어')\n(622, '로')\n(628, '시간')\n(629, '이')\n(633, '.')\n(636, '가')\n(641, '이')\n(644, '어')\n(645, '나')\n(651, '이')\n(655, '2')\n(656, '0')\n(657, '1')\n(658, '4')\n(659, '년')\n(665, '제')\n(669, '와')\n(678, '하')\n(679, '가')\n(685, '에')\n(687, '이')\n(692, '때')\n(695, '으로')\n(695, '로')\n(698, '이')\n(701, '.')\n(706, '에')\n(713, '년')\n(717, '가')\n(723, '1')\n(724, '4')\n(725, '5')\n(726, '0')\n(728, '8')\n(729, '9')\n(730, '3')\n(731, '9')\n(736, '을')\n(742, '.')\n(750, '영')\n(753, '자')\n(760, '@')\n(766, '.')\n(769, '.')\nNone\n"
     ]
    }
   ],
   "source": [
    "from Api.NewsDataService import NewsDataService\n",
    "newsList = NewsDataService().FetchNewsData(1)\n",
    "for news in newsList:\n",
    "    content = news.get_newsContent()\n",
    "    removed = StopwordsRemover(rawTxt=content).RemoveStopwordsFromContent()\n",
    "    print(removed)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string required",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-93822c16388f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_newsContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mremoved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStopwordsRemover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxtArr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRemoveStopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremoved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/softmarshmallow/Documents/Apps/Inked/EvilEye-NLP/StopwordsRemoval/StopwordsRemover.py\u001b[0m in \u001b[0;36mRemoveStopwords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# # Get new set with elements that are only in a but not in b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# removedStopwordsTextArr = targetTextArr.difference(removalTextArr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;31m# endregion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# region method2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string required"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "from WordTokenizer.WordTokenizer import WordTokenizer\n",
    "for news in newsList:\n",
    "    content = news.get_newsContent()\n",
    "    tokens = WordTokenizer(content).Tokenize()\n",
    "    removed = StopwordsRemover(txtArr=tokens).RemoveStopwords()\n",
    "    \n",
    "    pprint(removed)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
